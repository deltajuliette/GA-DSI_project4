{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94f4ef30",
   "metadata": {},
   "source": [
    "# Preprocessing, Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e1cd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing our libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from geopy.distance import geodesic\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (roc_auc_score, confusion_matrix, recall_score, precision_score, \n",
    "                             roc_curve, f1_score, plot_confusion_matrix)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3639988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring notebook remains tidy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9454796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting our seaborn style and palette\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('icefire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f253bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a custom function to kick-start the EDA process\n",
    "def eda_clean(df):\n",
    "    print('Dataset Statistics:')\n",
    "    print(f'Shape of dataframe: {df.shape}')\n",
    "    print('--------------------------------------')\n",
    "    print(f'Null values in dataframe: {df.isna().sum().sum()}')\n",
    "    print('--------------------------------------')\n",
    "    print(f'% of Null values in dataframe: {round(((df.isna().sum().sum())/(df.shape[0])) * 100, 2)}%')\n",
    "    print('--------------------------------------')\n",
    "    print(f\"Total duplicate rows: {df[df.duplicated()].shape[0]}\")\n",
    "    print('--------------------------------------')\n",
    "    print(f\"% duplicate rows: {round(df[df.duplicated()].shape[0] / df.shape[0] * 100, 2)}%\")\n",
    "    print(f'\\nColumn names: {df.columns}')\n",
    "    print('\\nVariable Types')\n",
    "    print(f\"Columns Count: \\n{df.dtypes.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e8693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our tidied train dataset\n",
    "train_transformed = pd.read_csv('../data/cleaned/train_tidied.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d360f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping redundant columns\n",
    "train_transformed.drop(columns=['date', 'addressnumberandstreet', 'year_month', 'station', 'station_ref', 'year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9c5101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping null and nan columns\n",
    "train_transformed.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014a7495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick snapshot of our final dataframe\n",
    "train_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and y variables for our train split\n",
    "X = train_transformed.drop(columns='wnvpresent')\n",
    "y = train_transformed['wnvpresent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977bc405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a train-test split of 70-30 for train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    stratify=y, # Because this is an unbalanced dataset\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3535f4ab",
   "metadata": {},
   "source": [
    "**Polynomial Features**\n",
    "\n",
    "We have accounted for the interactions between different features. Model results were not very different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a7d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generates the full polynomial feature table\n",
    "# pf = PolynomialFeatures(include_bias=False, degree=2)\n",
    "# X_train_pf = pf.fit_transform(X_train)\n",
    "\n",
    "# # Adds appropriate feature names to all polynomial features\n",
    "# X_train_pf = pd.DataFrame(X_train_pf, columns=pf.get_feature_names(X_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f550bc9a",
   "metadata": {},
   "source": [
    "**Solving the problem with an unbalanced dataset** \n",
    "\n",
    "In classification problems, balancing your data is absolutely crucial. Data is said to be imbalanced when instances of one class outnumber the other(s) by a large proportion. One of the sampling techniques that we have decided to employ is **SMOTE** (Synthetic Minority Over-Sampling Technique).\n",
    "\n",
    "Just like the name suggests, the technique generates synthetic data for the minority class. SMOTE proceeds by joining the points of the minority class with line segments and then places artificial points on these lines. Here's how it works:\n",
    "\n",
    "* Choose a minority class input vector\n",
    "* Find its k nearest neighbors (k_neighbors is specified as an argument in the SMOTE() function)\n",
    "* Choose one of these neighbors and place a synthetic point anywhere on the line joining the point under consideration and its chosen neighbor\n",
    "* Repeat the steps until data is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66fc91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to run model with standard scaling, SMOTE sampling, \n",
    "# with an option to run grid search, model and print results\n",
    "\n",
    "def run_model(mod, mod_params={}, grid_search=False):\n",
    "    \n",
    "    # Initial dictionary to hold model results\n",
    "    results = {}\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "            ('ss', StandardScaler()),\n",
    "            (mod, models[mod])\n",
    "            ])\n",
    "    \n",
    "    if grid_search:\n",
    "        # Instantiate list to store gridsearch results\n",
    "        gs = GridSearchCV(pipe, param_grid=mod_params, cv=5, verbose=1, scoring='roc_auc', n_jobs=-1)\n",
    "        gs.fit(X_train, y_train)\n",
    "        pipe = gs\n",
    "    else:\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "\n",
    "    # Retrieve metrics\n",
    "    predictions = pipe.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "    y_test_pred_prob = pipe.predict_proba(X_test)[:,1]\n",
    "    y_train_pred_prob = pipe.predict_proba(X_train)[:,1]\n",
    "    auc_scores = cross_val_score(pipe, X_train, y_train,  scoring='roc_auc', cv = 5)\n",
    "\n",
    "    results['model'] = mod\n",
    "    \n",
    "    results['train_auc_cv'] = auc_scores.mean()\n",
    "    \n",
    "    results['f1'] = f1_score(y_test, predictions)\n",
    "    results['recall'] = recall_score(y_test, predictions)        # % OF ACTUAL positives that are CORRECTLY predicted\n",
    "    results['precision'] = precision_score(y_test, predictions)  # % OF positives that are CORRECTLY predicted\n",
    "\n",
    "    results['train_auc'] = roc_auc_score(y_train, y_train_pred_prob)\n",
    "    results['test_auc'] = roc_auc_score(y_test, y_test_pred_prob)\n",
    "    results['auc_diff'] = results['train_auc'] - results['test_auc']\n",
    "\n",
    "    if grid_search:\n",
    "        gs_list.append(results)\n",
    "        print('### BEST PARAMS ###')\n",
    "        display(pipe.best_params_)\n",
    "        \n",
    "    else:\n",
    "        init_list.append(results)\n",
    "\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad13db53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X_train_copy = X_train.astype(float).copy()\n",
    "y_train_copy = y_train.astype(float).copy()\n",
    "\n",
    "# create loop to run SMOTE sampling and compare the modelling outcomes with and without it\n",
    "for k in ['No', 'SMOTE']:\n",
    "    print('\\nMethod Used: {}'.format(k + ' sampling'), \"-\" * 100)\n",
    "        \n",
    "    print('\\nClass Balance BEFORE')\n",
    "    display(y_train.value_counts(normalize=True))\n",
    "    print('Number of rows: {}'.format(y_train.shape[0]))\n",
    "  \n",
    "    # instiantiate the models\n",
    "    methods = {'SMOTE': SMOTE(random_state=42)}\n",
    "    \n",
    "    if k == 'SMOTE':\n",
    "        mthd = methods[k]\n",
    "        X_train, y_train = mthd.fit_resample(X_train, y_train)\n",
    "\n",
    "    print('\\nClass Balance AFTER')\n",
    "    display(y_train.value_counts(normalize=True))\n",
    "    print('Number of rows: {}'.format(y_train.shape[0]),'\\n')\n",
    "    \n",
    "    \n",
    "    # Instiantiate models\n",
    "    models = {'lr': LogisticRegression(max_iter=5_000, random_state=42, solver='saga'),\n",
    "#               'rf': RandomForestClassifier(random_state=42),\n",
    "#               'gb': GradientBoostingClassifier(random_state=42),\n",
    "#               'dt': DecisionTreeClassifier(random_state=42),\n",
    "#               'et': ExtraTreesClassifier(random_state=42),\n",
    "#               'ada': AdaBoostClassifier(random_state=42),\n",
    "#               'svc': SVC(random_state=42, probability=True),\n",
    "              'xgb': XGBClassifier(random_state=42, \n",
    "                              objective='binary:logistic', \n",
    "                              verbosity=1, n_jobs=-1)\n",
    "            }\n",
    "\n",
    "    # Instantiate lists to store results\n",
    "    init_list = []\n",
    "    gs_list = []\n",
    "\n",
    "    for m in models:\n",
    "        run_model(m)\n",
    "    result_df = pd.DataFrame(init_list).sort_values(by=[\"f1\"], ascending=False).reset_index(drop=True)\n",
    "    display(result_df)\n",
    "\n",
    "    X_train = X_train_copy\n",
    "    y_train = y_train_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bb641d",
   "metadata": {},
   "source": [
    "## Selection of our final model (XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c63a4f",
   "metadata": {},
   "source": [
    "Due to the unbalanced nature of this dataset, the main metric on our radar is the ROC AUC. **XGBoost** fares scores pretty well on the validation set and requires less computational input compared to **ADABoost**.\n",
    "\n",
    "We will create a pipeline and tune some hyperparameters below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab6a477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pipeline model for StandardScaler, SMOTE and XGBoost\n",
    "xgb_pipe = Pipeline([\n",
    "        ('ss', StandardScaler()),\n",
    "        ('xgb', XGBClassifier(random_state=42, \n",
    "                              objective= 'binary:logistic', \n",
    "                              verbosity=1, n_jobs=-1))\n",
    "    ])\n",
    "# Parameters\n",
    "xgb_params = {  'xgb__learning_rate': [0.1],\n",
    "                'xgb__max_depth': [40],\n",
    "                'xgb__min_child_weight': [25],\n",
    "                'xgb__gamma': [0.85],\n",
    "                'xgb__subsample': [1],\n",
    "                'xgb__scale_pos_weight': [63],\n",
    "                'xgb__n_estimators': [49]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8992a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "xgb_best = run_model('xgb', xgb_params, grid_search=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79bbd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table to show the predictors with the highest importance (i.e. strongest predictors of the presence of WNV)\n",
    "feature_names = X.columns\n",
    "coefficients = pd.DataFrame(np.squeeze(xgb_best.best_estimator_.named_steps[\"xgb\"].feature_importances_),\n",
    "                            columns=['Importances']) \n",
    "features = pd.DataFrame(np.squeeze(feature_names), columns=['Features']) \n",
    "df = pd.concat([features, coefficients], axis='columns').sort_values('Importances', ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c6f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = xgb_best.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve, ROC AUC Score: {}'.format(roc_auc_score(y_test, y_pred_prob).round(3)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184af3de",
   "metadata": {},
   "source": [
    "## Tidying ```test``` data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5a0490",
   "metadata": {},
   "source": [
    "We will need to import our test data and carry out the pre-requisite pre-processing steps. We have created custom functions for this bit of the codebook.\n",
    "* Initial cleaning (Dropping address, block, street, addressaccuracy columns)\n",
    "* Date feature engineering (Extracting year, month, week, day variables)\n",
    "* Dummify our ```cluster``` column\n",
    "* One-hot encoding mosquito species\n",
    "* Determining if a coordinate is closer to Station 1 or Station 2\n",
    "* Final cleaning (Dropping the remaining unnecessary columns)\n",
    "* Generating predictions from our best model\n",
    "\n",
    "After applying each function, we will map it to a new variable to ensure the process flows smoothly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2eedcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train and test datasets\n",
    "test = pd.read_csv('../data/cleaned/test_tidied.csv', parse_dates=['date'])\n",
    "\n",
    "# Converting columns to lowercase for standardisation\n",
    "test.columns = test.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ea42d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previewing our test dataset\n",
    "eda_clean(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ff6a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_clean(df):\n",
    "    df.drop(columns=['address', 'block', 'street', 'addressaccuracy'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c57ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter1 = initial_clean(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4804972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_feature_engineering(df):\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['week'] = df['date'].dt.isocalendar().week\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['year_month'] = df['date'].dt.strftime(\"%Y-%m\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895676e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter2 = date_feature_engineering(test_iter1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df4a96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter3 = pd.get_dummies(test_iter2, columns=['cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683cc2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can exclude Unsepcified species from this selection\n",
    "species_of_interest = ['RESTUANS', 'PIPIENS', \n",
    "                       'SALINARIUS', 'TERRITANS', 'TARSALIS', 'ERRATICUS'\n",
    "                      ]\n",
    "\n",
    "# create loop to create dummified variables to indicate presence of Pipiens & Restuans species\n",
    "def dummify_species(df):\n",
    "    for i in species_of_interest:\n",
    "        df[i] = df['species'].apply(lambda x: 1 if i in x else 0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c1dd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter4 = dummify_species(test_iter3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d165be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_station(lat, long):\n",
    "    station1 = (41.995, -87.933) #Chicago O'Hare Tntl Airpot -> lat: 41.995 long: -87.933\n",
    "    station2 = (41.786, -87.752) #Chicago Midway Tntl Airpot -> lat: 41.786 long: -87.752\n",
    "    coordinates = (lat, long)\n",
    "    \n",
    "    return 1 if geodesic(coordinates, station1) < geodesic(coordinates, station2) else 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb335dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Apply function to map our function\n",
    "test_iter4['station_ref'] = test_iter4.apply(lambda i: determine_station(i['latitude'], i['longitude']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5181f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tidied weather dataset\n",
    "weather_tidied = pd.read_csv('../data/cleaned/weather_tidied.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572cdbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter5 = test_iter4.merge(weather_tidied, how='left', left_on=['station_ref', 'date'], right_on=['station', 'date'])\n",
    "test_iter5.drop(columns=[\"station\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ac4199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_clean(df):\n",
    "    df.drop(columns=['species', 'trap', 'date', 'addressnumberandstreet', \n",
    "                     'latitude', 'longitude', \n",
    "                     'day', 'coord',\n",
    "                     'year_month', 'station_ref', 'year'], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262505d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter6 = final_clean(test_iter5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a2b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_best(df, model_best):\n",
    "    df_id = df['id']\n",
    "\n",
    "    df_base = df.drop(columns=['id'])\n",
    "    \n",
    "    # generate predictions\n",
    "    y_pred = model_best.best_estimator_.predict(df_base)  \n",
    "\n",
    "    # load prediction into dataframe\n",
    "    df_pred = pd.DataFrame(y_pred, columns=['wnvpresent']) \n",
    "\n",
    "    # Merge id with predictions into one dataframe\n",
    "    df_final = pd.concat([df_id, df_pred], axis='columns')\n",
    "    return df_final\n",
    "\n",
    "def predict_proba_best(df, model_best):\n",
    "    df_coord = test[['latitude', 'longitude']]\n",
    "    \n",
    "    df_base = df.drop(columns=['id'])\n",
    "    \n",
    "    # generate predictions\n",
    "    y_pred = model_best.best_estimator_.predict_proba(df_base)  \n",
    "\n",
    "    # load prediction into dataframe\n",
    "    df_pred = pd.DataFrame(np.squeeze(y_pred)) \n",
    "\n",
    "    # Merge id with predictions into one dataframe\n",
    "    df_final = pd.concat([df_coord, df_pred], axis='columns')\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdcad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions\n",
    "pred = predict_best(test_iter6, xgb_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a56a724",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.rename(columns={'id': 'Id', 'wnvpresent':'WnvPresent'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b92ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.set_index('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320e2abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_csv('../kaggle/submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67897e90",
   "metadata": {},
   "source": [
    "**Kaggle Submission Score**\n",
    "\n",
    "**Thoughts**: We believe further improvements can be made to the model (if given enough time). Here are some of our considerations:\n",
    "* There could be a bias for certain traps (Given that a particular trap may always capture more mosquitos, etc)\n",
    "* Possibility of a daily multiplier given an array of outbreaks; Outbreaks will possibly influence the days before and after it (They tend to cluster in the dimension of time too)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26adaefc",
   "metadata": {},
   "source": [
    "![Our Kaggle submission](../images/kaggle_submission.png \"Our Kaggle submission\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
