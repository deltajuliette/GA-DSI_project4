{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94f4ef30",
   "metadata": {},
   "source": [
    "# Preprocessing, Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58e1cd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing our libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from geopy.distance import geodesic\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (roc_auc_score, confusion_matrix, recall_score, precision_score, \n",
    "                             roc_curve, f1_score, plot_confusion_matrix)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3639988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring notebook remains tidy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9454796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting our seaborn style and palette\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('icefire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f253bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a custom function to kick-start the EDA process\n",
    "def eda_clean(df):\n",
    "    print('Dataset Statistics:')\n",
    "    print(f'Shape of dataframe: {df.shape}')\n",
    "    print('--------------------------------------')\n",
    "    print(f'Null values in dataframe: {df.isna().sum().sum()}')\n",
    "    print('--------------------------------------')\n",
    "    print(f'% of Null values in dataframe: {round(((df.isna().sum().sum())/(df.shape[0])) * 100, 2)}%')\n",
    "    print('--------------------------------------')\n",
    "    print(f\"Total duplicate rows: {df[df.duplicated()].shape[0]}\")\n",
    "    print('--------------------------------------')\n",
    "    print(f\"% duplicate rows: {round(df[df.duplicated()].shape[0] / df.shape[0] * 100, 2)}%\")\n",
    "    print(f'\\nColumn names: {df.columns}')\n",
    "    print('\\nVariable Types')\n",
    "    print(f\"Columns Count: \\n{df.dtypes.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5e8693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our tidied train dataset\n",
    "train_transformed = pd.read_csv('../data/cleaned/train_tidied.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d360f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping redundant columns\n",
    "train_transformed.drop(columns=['date', 'addressnumberandstreet', 'year_month', 'station', 'station_ref', 'year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25f9eed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping null and nan columns\n",
    "train_transformed.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffcc1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and y variables for our train split\n",
    "X = train_transformed.drop(columns='wnvpresent')\n",
    "y = train_transformed['wnvpresent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "977bc405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a train-test split of 70-30 for train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    stratify=y, # Because this is an unbalanced dataset\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d74a7d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generates the full polynomial feature table\n",
    "# pf = PolynomialFeatures(include_bias=False, degree=2)\n",
    "# X_train_pf = pf.fit_transform(X_train)\n",
    "\n",
    "# # Adds appropriate feature names to all polynomial features\n",
    "# X_train_pf = pd.DataFrame(X_train_pf, columns=pf.get_feature_names(X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d66fc91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to run model with standard scaling, SMOTE sampling, \n",
    "# with an option to run grid search, model and print results\n",
    "\n",
    "def run_model(mod, mod_params={}, grid_search=False):\n",
    "    \n",
    "    # Initial dictionary to hold model results\n",
    "    results = {}\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "            ('ss', StandardScaler()),\n",
    "            (mod, models[mod])\n",
    "            ])\n",
    "    \n",
    "    if grid_search:\n",
    "        # Instantiate list to store gridsearch results\n",
    "        gs = GridSearchCV(pipe, param_grid=mod_params, cv=5, verbose=1, scoring='roc_auc', n_jobs=-1)\n",
    "        gs.fit(X_train, y_train)\n",
    "        pipe = gs\n",
    "    else:\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "\n",
    "    # Retrieve metrics\n",
    "    predictions = pipe.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "    y_test_pred_prob = pipe.predict_proba(X_test)[:,1]\n",
    "    y_train_pred_prob = pipe.predict_proba(X_train)[:,1]\n",
    "    auc_scores = cross_val_score(pipe, X_train, y_train,  scoring='roc_auc', cv = 5)\n",
    "\n",
    "    results['model'] = mod\n",
    "    \n",
    "    results['train_auc_cv'] = auc_scores.mean()\n",
    "    \n",
    "    results['f1'] = f1_score(y_test, predictions)\n",
    "    results['recall'] = recall_score(y_test, predictions)        # % OF ACTUAL positives that are CORRECTLY predicted\n",
    "    results['precision'] = precision_score(y_test, predictions)  # % OF positives that are CORRECTLY predicted\n",
    "\n",
    "    results['train_auc'] = roc_auc_score(y_train, y_train_pred_prob)\n",
    "    results['test_auc'] = roc_auc_score(y_test, y_test_pred_prob)\n",
    "    results['auc_diff'] = results['train_auc'] - results['test_auc']\n",
    "\n",
    "    if grid_search:\n",
    "        gs_list.append(results)\n",
    "        print('### BEST PARAMS ###')\n",
    "        display(pipe.best_params_)\n",
    "        \n",
    "    else:\n",
    "        init_list.append(results)\n",
    "\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad13db53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Method Used: No sampling ----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Class Balance BEFORE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.945643\n",
       "1    0.054357\n",
       "Name: wnvpresent, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 5887\n",
      "\n",
      "Class Balance AFTER\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.945643\n",
       "1    0.054357\n",
       "Name: wnvpresent, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 5887 \n",
      "\n",
      "[19:49:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:49:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:49:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:49:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:49:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:49:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_auc_cv</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>auc_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gb</td>\n",
       "      <td>0.840480</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.887527</td>\n",
       "      <td>0.827499</td>\n",
       "      <td>0.060027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dt</td>\n",
       "      <td>0.796072</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.903984</td>\n",
       "      <td>0.767932</td>\n",
       "      <td>0.136051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>et</td>\n",
       "      <td>0.795216</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.903984</td>\n",
       "      <td>0.766027</td>\n",
       "      <td>0.137956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.825842</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.903528</td>\n",
       "      <td>0.818645</td>\n",
       "      <td>0.084883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.798006</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.777536</td>\n",
       "      <td>0.126114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.801566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.817895</td>\n",
       "      <td>0.790806</td>\n",
       "      <td>0.027089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.838430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.871348</td>\n",
       "      <td>0.828083</td>\n",
       "      <td>0.043265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svc</td>\n",
       "      <td>0.743474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769611</td>\n",
       "      <td>0.697245</td>\n",
       "      <td>0.072365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  train_auc_cv        f1    recall  precision  train_auc  test_auc  \\\n",
       "0    gb      0.840480  0.014388  0.007299   0.500000   0.887527  0.827499   \n",
       "1    dt      0.796072  0.014388  0.007299   0.500000   0.903984  0.767932   \n",
       "2    et      0.795216  0.014388  0.007299   0.500000   0.903984  0.766027   \n",
       "3   xgb      0.825842  0.014388  0.007299   0.500000   0.903528  0.818645   \n",
       "4    rf      0.798006  0.014286  0.007299   0.333333   0.903650  0.777536   \n",
       "5    lr      0.801566  0.000000  0.000000   0.000000   0.817895  0.790806   \n",
       "6   ada      0.838430  0.000000  0.000000   0.000000   0.871348  0.828083   \n",
       "7   svc      0.743474  0.000000  0.000000   0.000000   0.769611  0.697245   \n",
       "\n",
       "   auc_diff  \n",
       "0  0.060027  \n",
       "1  0.136051  \n",
       "2  0.137956  \n",
       "3  0.084883  \n",
       "4  0.126114  \n",
       "5  0.027089  \n",
       "6  0.043265  \n",
       "7  0.072365  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Method Used: SMOTE sampling ----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Class Balance BEFORE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.945643\n",
       "1.0    0.054357\n",
       "Name: wnvpresent, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 5887\n",
      "\n",
      "Class Balance AFTER\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.5\n",
       "1.0    0.5\n",
       "Name: wnvpresent, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 11134 \n",
      "\n",
      "[19:51:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:51:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:51:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:51:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:51:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:51:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_auc_cv</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>auc_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.954666</td>\n",
       "      <td>0.278481</td>\n",
       "      <td>0.562044</td>\n",
       "      <td>0.185096</td>\n",
       "      <td>0.962982</td>\n",
       "      <td>0.771542</td>\n",
       "      <td>0.191439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.928561</td>\n",
       "      <td>0.278184</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.173993</td>\n",
       "      <td>0.931800</td>\n",
       "      <td>0.816479</td>\n",
       "      <td>0.115322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dt</td>\n",
       "      <td>0.954548</td>\n",
       "      <td>0.270370</td>\n",
       "      <td>0.532847</td>\n",
       "      <td>0.181141</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.763963</td>\n",
       "      <td>0.199541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>et</td>\n",
       "      <td>0.953787</td>\n",
       "      <td>0.269871</td>\n",
       "      <td>0.532847</td>\n",
       "      <td>0.180693</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.762107</td>\n",
       "      <td>0.201397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.959170</td>\n",
       "      <td>0.268336</td>\n",
       "      <td>0.547445</td>\n",
       "      <td>0.177725</td>\n",
       "      <td>0.963382</td>\n",
       "      <td>0.812113</td>\n",
       "      <td>0.151268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gb</td>\n",
       "      <td>0.947904</td>\n",
       "      <td>0.262751</td>\n",
       "      <td>0.620438</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.951018</td>\n",
       "      <td>0.811792</td>\n",
       "      <td>0.139226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>svc</td>\n",
       "      <td>0.912391</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.154976</td>\n",
       "      <td>0.921335</td>\n",
       "      <td>0.812503</td>\n",
       "      <td>0.108831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.824658</td>\n",
       "      <td>0.214365</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.126302</td>\n",
       "      <td>0.826088</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.050807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  train_auc_cv        f1    recall  precision  train_auc  test_auc  \\\n",
       "0    rf      0.954666  0.278481  0.562044   0.185096   0.962982  0.771542   \n",
       "1   ada      0.928561  0.278184  0.693431   0.173993   0.931800  0.816479   \n",
       "2    dt      0.954548  0.270370  0.532847   0.181141   0.963504  0.763963   \n",
       "3    et      0.953787  0.269871  0.532847   0.180693   0.963504  0.762107   \n",
       "4   xgb      0.959170  0.268336  0.547445   0.177725   0.963382  0.812113   \n",
       "5    gb      0.947904  0.262751  0.620438   0.166667   0.951018  0.811792   \n",
       "6   svc      0.912391  0.253333  0.693431   0.154976   0.921335  0.812503   \n",
       "7    lr      0.824658  0.214365  0.708029   0.126302   0.826088  0.775281   \n",
       "\n",
       "   auc_diff  \n",
       "0  0.191439  \n",
       "1  0.115322  \n",
       "2  0.199541  \n",
       "3  0.201397  \n",
       "4  0.151268  \n",
       "5  0.139226  \n",
       "6  0.108831  \n",
       "7  0.050807  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train_copy = X_train.astype(float).copy()\n",
    "y_train_copy = y_train.astype(float).copy()\n",
    "\n",
    "# create loop to run SMOTE sampling and compare the modelling outcomes with and without it\n",
    "for k in ['No', 'SMOTE']:\n",
    "    print('\\nMethod Used: {}'.format(k + ' sampling'), \"-\" * 100)\n",
    "        \n",
    "    print('\\nClass Balance BEFORE')\n",
    "    display(y_train.value_counts(normalize=True))\n",
    "    print('Number of rows: {}'.format(y_train.shape[0]))\n",
    "  \n",
    "    # instiantiate the models\n",
    "    methods = {'SMOTE': SMOTE(random_state=42)}\n",
    "    \n",
    "    if k == 'SMOTE':\n",
    "        mthd = methods[k]\n",
    "        X_train, y_train = mthd.fit_resample(X_train, y_train)\n",
    "\n",
    "    print('\\nClass Balance AFTER')\n",
    "    display(y_train.value_counts(normalize=True))\n",
    "    print('Number of rows: {}'.format(y_train.shape[0]),'\\n')\n",
    "    \n",
    "    \n",
    "    # Instiantiate models\n",
    "    models = {'lr': LogisticRegression(max_iter=5_000, random_state=42, solver='saga'),\n",
    "              'rf': RandomForestClassifier(random_state=42),\n",
    "              'gb': GradientBoostingClassifier(random_state=42),\n",
    "              'dt': DecisionTreeClassifier(random_state=42),\n",
    "              'et': ExtraTreesClassifier(random_state=42),\n",
    "              'ada': AdaBoostClassifier(random_state=42),\n",
    "              'svc': SVC(random_state=42, probability=True),\n",
    "              'xgb': XGBClassifier(random_state=42, \n",
    "                              objective='binary:logistic', \n",
    "                              verbosity=1, n_jobs=-1)\n",
    "            }\n",
    "\n",
    "    # Instantiate lists to store results\n",
    "    init_list = []\n",
    "    gs_list = []\n",
    "\n",
    "    for m in models:\n",
    "        run_model(m)\n",
    "    result_df = pd.DataFrame(init_list).sort_values(by=[\"f1\"], ascending=False).reset_index(drop=True)\n",
    "    display(result_df)\n",
    "\n",
    "    X_train = X_train_copy\n",
    "    y_train = y_train_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bb641d",
   "metadata": {},
   "source": [
    "## Selection of our final model (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cab6a477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pipeline model for StandardScaler, SMOTE and XGBoost\n",
    "xgb_pipe = Pipeline([\n",
    "        ('ss', StandardScaler()),\n",
    "        ('xgb', XGBClassifier(random_state=42, \n",
    "                              objective= 'binary:logistic', \n",
    "                              verbosity=1, n_jobs=-1))\n",
    "    ])\n",
    "# Parameters\n",
    "xgb_params = {  'xgb__learning_rate': [0.1],\n",
    "                'xgb__max_depth': [50],\n",
    "                'xgb__min_child_weight': [25],\n",
    "                'xgb__gamma': [0.85],\n",
    "                'xgb__subsample': [1],\n",
    "                'xgb__scale_pos_weight': [63],\n",
    "                'xgb__n_estimators': [49]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8992a8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[19:52:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[19:52:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[19:52:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[19:52:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[19:52:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[19:52:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "### BEST PARAMS ###\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'xgb__gamma': 0.85,\n",
       " 'xgb__learning_rate': 0.1,\n",
       " 'xgb__max_depth': 50,\n",
       " 'xgb__min_child_weight': 25,\n",
       " 'xgb__n_estimators': 49,\n",
       " 'xgb__scale_pos_weight': 63,\n",
       " 'xgb__subsample': 1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgb_best = run_model('xgb', xgb_params, grid_search=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7996273a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>week</td>\n",
       "      <td>0.260906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>raining</td>\n",
       "      <td>0.069774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIPIENS</td>\n",
       "      <td>0.057277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>humidity_10ma</td>\n",
       "      <td>0.055098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>misty_5sum</td>\n",
       "      <td>0.048477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>month</td>\n",
       "      <td>0.048215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>avgspeed</td>\n",
       "      <td>0.043690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>avgspeed_10ma</td>\n",
       "      <td>0.040667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>humidity_5ma</td>\n",
       "      <td>0.032045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>preciptotal_5ma</td>\n",
       "      <td>0.028993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>stnpressure_5ma</td>\n",
       "      <td>0.027394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tavg_10ma</td>\n",
       "      <td>0.025904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>stnpressure_10ma</td>\n",
       "      <td>0.024502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>humidity</td>\n",
       "      <td>0.022592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>misty_10sum</td>\n",
       "      <td>0.021564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>avgspeed_5ma</td>\n",
       "      <td>0.021498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tavg</td>\n",
       "      <td>0.020125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>raining_5sum</td>\n",
       "      <td>0.019754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>preciptotal_10ma</td>\n",
       "      <td>0.017706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>trange_5ma</td>\n",
       "      <td>0.017077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tavg_5ma</td>\n",
       "      <td>0.016249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>day</td>\n",
       "      <td>0.013884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>trange_10ma</td>\n",
       "      <td>0.013614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>trange</td>\n",
       "      <td>0.012919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>misty</td>\n",
       "      <td>0.010390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stnpressure</td>\n",
       "      <td>0.009767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RESTUANS</td>\n",
       "      <td>0.009152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>preciptotal</td>\n",
       "      <td>0.005591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>raining_10sum</td>\n",
       "      <td>0.005175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TARSALIS</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SALINARIUS</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ERRATICUS</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>preciptotal_5sum</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>preciptotal_10sum</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TERRITANS</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Features  Importances\n",
       "1                week     0.260906\n",
       "13            raining     0.069774\n",
       "4             PIPIENS     0.057277\n",
       "27      humidity_10ma     0.055098\n",
       "31         misty_5sum     0.048477\n",
       "0               month     0.048215\n",
       "12           avgspeed     0.043690\n",
       "26      avgspeed_10ma     0.040667\n",
       "21       humidity_5ma     0.032045\n",
       "22    preciptotal_5ma     0.028993\n",
       "19    stnpressure_5ma     0.027394\n",
       "23          tavg_10ma     0.025904\n",
       "25   stnpressure_10ma     0.024502\n",
       "15           humidity     0.022592\n",
       "34        misty_10sum     0.021564\n",
       "20       avgspeed_5ma     0.021498\n",
       "9                tavg     0.020125\n",
       "30       raining_5sum     0.019754\n",
       "28   preciptotal_10ma     0.017706\n",
       "18         trange_5ma     0.017077\n",
       "17           tavg_5ma     0.016249\n",
       "2                 day     0.013884\n",
       "24        trange_10ma     0.013614\n",
       "16             trange     0.012919\n",
       "14              misty     0.010390\n",
       "11        stnpressure     0.009767\n",
       "3            RESTUANS     0.009152\n",
       "10        preciptotal     0.005591\n",
       "33      raining_10sum     0.005175\n",
       "7            TARSALIS     0.000000\n",
       "5          SALINARIUS     0.000000\n",
       "8           ERRATICUS     0.000000\n",
       "29   preciptotal_5sum     0.000000\n",
       "32  preciptotal_10sum     0.000000\n",
       "6           TERRITANS     0.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create table to show the predictors with the highest importance (i.e. strongest predictors of the presence of WNV)\n",
    "feature_names = X.columns\n",
    "coefficients = pd.DataFrame(np.squeeze(xgb_best.best_estimator_.named_steps[\"xgb\"].feature_importances_),\n",
    "                            columns=['Importances']) \n",
    "features = pd.DataFrame(np.squeeze(feature_names), columns=['Features']) \n",
    "df = pd.concat([features, coefficients], axis='columns').sort_values('Importances', ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77c6f709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_prob = xgb_best.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve, ROC AUC Score: {}'.format(roc_auc_score(y_test, y_pred_prob).round(3)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184af3de",
   "metadata": {},
   "source": [
    "## Tidying ```test``` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf2eedcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train and test datasets\n",
    "test = pd.read_csv('../data/raw/test.csv', parse_dates=['Date'])\n",
    "\n",
    "# Converting columns to lowercase for standardisation\n",
    "test.columns = test.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6ea42d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics:\n",
      "Shape of dataframe: (116293, 11)\n",
      "--------------------------------------\n",
      "Null values in dataframe: 0\n",
      "--------------------------------------\n",
      "% of Null values in dataframe: 0.0%\n",
      "--------------------------------------\n",
      "Total duplicate rows: 0\n",
      "--------------------------------------\n",
      "% duplicate rows: 0.0%\n",
      "\n",
      "Column names: Index(['id', 'date', 'address', 'species', 'block', 'street', 'trap',\n",
      "       'addressnumberandstreet', 'latitude', 'longitude', 'addressaccuracy'],\n",
      "      dtype='object')\n",
      "\n",
      "Variable Types\n",
      "Columns Count: \n",
      "object            5\n",
      "int64             3\n",
      "float64           2\n",
      "datetime64[ns]    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Previewing our test dataset\n",
    "eda_clean(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55ff6a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_clean(df):\n",
    "    df.drop(columns=['address', 'block', 'street', 'addressaccuracy'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c57ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter1 = initial_clean(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4804972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_feature_engineering(df):\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['week'] = df['date'].dt.isocalendar().week\n",
    "    df['day'] = df['date'].dt.isocalendar().day\n",
    "    df['year_month'] = df['date'].dt.strftime(\"%Y-%m\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "895676e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter2 = date_feature_engineering(test_iter1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "683cc2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can exclude Unsepcified species from this selection\n",
    "species_of_interest = ['RESTUANS', 'PIPIENS', 'SALINARIUS', 'TERRITANS', 'TARSALIS', 'ERRATICUS']\n",
    "\n",
    "# create loop to create dummified variables to indicate presence of Pipiens & Restuans species\n",
    "def dummify_species(df):\n",
    "    for i in species_of_interest:\n",
    "        df[i] = df['species'].apply(lambda x: 1 if i in x else 0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3c1dd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter3 = dummify_species(test_iter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d165be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_station(lat, long):\n",
    "    station1 = (41.995, -87.933) #Chicago O'Hare Tntl Airpot -> lat: 41.995 long: -87.933\n",
    "    station2 = (41.786, -87.752) #Chicago Midway Tntl Airpot -> lat: 41.786 long: -87.752\n",
    "    coordinates = (lat, long)\n",
    "    \n",
    "    return 1 if geodesic(coordinates, station1) < geodesic(coordinates, station2) else 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb335dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 56.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Apply function to map our function\n",
    "test_iter3['station_ref'] = test_iter3.apply(lambda i: determine_station(i['latitude'], i['longitude']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5181f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_tidied = pd.read_csv('../data/cleaned/weather_tidied.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "572cdbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter4 = test_iter3.merge(weather_tidied, how='left', left_on=['station_ref', 'date'], right_on=['station', 'date'])\n",
    "test_iter4.drop(columns=[\"station\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5ac4199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_clean(df):\n",
    "    df.drop(columns=['species', 'trap', 'date', 'addressnumberandstreet', \n",
    "                     'latitude', 'longitude', \n",
    "#                      'day', \n",
    "                     'year_month', 'station_ref', 'year'], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "262505d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter5 = final_clean(test_iter4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8020af33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df):\n",
    "    df_id = df['id']\n",
    "\n",
    "    df_base = df.drop(columns=['id'])\n",
    "    \n",
    "    # generate predictions\n",
    "    y_pred = ada_best.best_estimator_.predict(df_base)  \n",
    "\n",
    "    # load prediction into dataframe\n",
    "    df_pred = pd.DataFrame(np.squeeze(y_pred), columns=['wnvpresent']) \n",
    "\n",
    "    # Merge id with predictions into one dataframe\n",
    "    df_final = pd.concat([df_id, df_pred], axis='columns')\n",
    "    return df_final\n",
    "\n",
    "def predict_proba(df):\n",
    "    df_coord = test[['latitude', 'longitude']]\n",
    "    \n",
    "    df_base = df.drop(columns=['id'])\n",
    "    \n",
    "    # generate predictions\n",
    "    y_pred = ada_best.best_estimator_.predict_proba(df_base)  \n",
    "\n",
    "    # load prediction into dataframe\n",
    "    df_pred = pd.DataFrame(np.squeeze(y_pred)) \n",
    "\n",
    "    # Merge id with predictions into one dataframe\n",
    "    df_final = pd.concat([df_coord, df_pred], axis='columns')\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b7a2b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_best(df, model_best):\n",
    "    df_id = df['id']\n",
    "\n",
    "    df_base = df.drop(columns=['id'])\n",
    "    \n",
    "    # generate predictions\n",
    "    y_pred = model_best.best_estimator_.predict(df_base)  \n",
    "\n",
    "    # load prediction into dataframe\n",
    "    df_pred = pd.DataFrame(np.squeeze(y_pred), columns=['wnvpresent']) \n",
    "\n",
    "    # Merge id with predictions into one dataframe\n",
    "    df_final = pd.concat([df_id, df_pred], axis='columns')\n",
    "    return df_final\n",
    "\n",
    "def predict_proba_best(df, model_best):\n",
    "    df_coord = test[['latitude', 'longitude']]\n",
    "    \n",
    "    df_base = df.drop(columns=['id'])\n",
    "    \n",
    "    # generate predictions\n",
    "    y_pred = model_best.best_estimator_.predict_proba(df_base)  \n",
    "\n",
    "    # load prediction into dataframe\n",
    "    df_pred = pd.DataFrame(np.squeeze(y_pred)) \n",
    "\n",
    "    # Merge id with predictions into one dataframe\n",
    "    df_final = pd.concat([df_coord, df_pred], axis='columns')\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afdcad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions\n",
    "pred = predict_best(test_iter5, xgb_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a56a724",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.rename(columns={'id': 'Id', 'wnvpresent':'WnvPresent'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36b92ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.set_index('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "320e2abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_csv('../kaggle/submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67897e90",
   "metadata": {},
   "source": [
    "**Kaggle Submission Score**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26adaefc",
   "metadata": {},
   "source": [
    "![Our Kaggle submission](../images/kaggle_submission.png \"Our Kaggle submission\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
