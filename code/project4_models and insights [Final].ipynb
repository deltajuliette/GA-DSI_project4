{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94f4ef30",
   "metadata": {},
   "source": [
    "# Preprocessing, Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58e1cd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing our libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from geopy.distance import geodesic\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (roc_auc_score, confusion_matrix, recall_score, precision_score, \n",
    "                             roc_curve, f1_score, plot_confusion_matrix)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3639988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring notebook remains tidy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9454796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting our seaborn style and palette\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('icefire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f253bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a custom function to kick-start the EDA process\n",
    "def eda_clean(df):\n",
    "    print('Dataset Statistics:')\n",
    "    print(f'Shape of dataframe: {df.shape}')\n",
    "    print('--------------------------------------')\n",
    "    print(f'Null values in dataframe: {df.isna().sum().sum()}')\n",
    "    print('--------------------------------------')\n",
    "    print(f'% of Null values in dataframe: {round(((df.isna().sum().sum())/(df.shape[0])) * 100, 2)}%')\n",
    "    print('--------------------------------------')\n",
    "    print(f\"Total duplicate rows: {df[df.duplicated()].shape[0]}\")\n",
    "    print('--------------------------------------')\n",
    "    print(f\"% duplicate rows: {round(df[df.duplicated()].shape[0] / df.shape[0] * 100, 2)}%\")\n",
    "    print(f'\\nColumn names: {df.columns}')\n",
    "    print('\\nVariable Types')\n",
    "    print(f\"Columns Count: \\n{df.dtypes.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5e8693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our tidied train dataset\n",
    "train_transformed = pd.read_csv('../assets/cleaned/train_tidied.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d360f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping redundant columns\n",
    "train_transformed.drop(columns=['date', 'addressnumberandstreet', 'year_month', 'station', 'station_ref', 'year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb9c5101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping null and nan columns\n",
    "train_transformed.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "014a7495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wnvpresent</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>cluster_0</th>\n",
       "      <th>cluster_1</th>\n",
       "      <th>cluster_2</th>\n",
       "      <th>cluster_3</th>\n",
       "      <th>cluster_4</th>\n",
       "      <th>cluster_5</th>\n",
       "      <th>cluster_6</th>\n",
       "      <th>...</th>\n",
       "      <th>TERRITANS</th>\n",
       "      <th>TARSALIS</th>\n",
       "      <th>ERRATICUS</th>\n",
       "      <th>tavg</th>\n",
       "      <th>preciptotal</th>\n",
       "      <th>sealevel</th>\n",
       "      <th>resultspeed</th>\n",
       "      <th>resultdir</th>\n",
       "      <th>humidity</th>\n",
       "      <th>trange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.09</td>\n",
       "      <td>5.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>53.799129</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.09</td>\n",
       "      <td>5.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>53.799129</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.09</td>\n",
       "      <td>5.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>53.799129</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.09</td>\n",
       "      <td>5.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>53.799129</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.09</td>\n",
       "      <td>5.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>53.799129</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wnvpresent  month  week  cluster_0  cluster_1  cluster_2  cluster_3  \\\n",
       "0           0      5    22          0          0          0          1   \n",
       "1           0      5    22          0          0          0          1   \n",
       "2           0      5    22          0          0          0          1   \n",
       "3           0      5    22          0          0          0          0   \n",
       "4           0      5    22          0          0          0          0   \n",
       "\n",
       "   cluster_4  cluster_5  cluster_6  ...  TERRITANS  TARSALIS  ERRATICUS  tavg  \\\n",
       "0          0          0          0  ...          0         0          0  77.0   \n",
       "1          0          0          0  ...          0         0          0  77.0   \n",
       "2          0          0          0  ...          0         0          0  77.0   \n",
       "3          1          0          0  ...          0         0          0  77.0   \n",
       "4          0          0          1  ...          0         0          0  77.0   \n",
       "\n",
       "   preciptotal  sealevel  resultspeed  resultdir   humidity  trange  \n",
       "0          0.0     30.09          5.8       16.0  53.799129    23.0  \n",
       "1          0.0     30.09          5.8       16.0  53.799129    23.0  \n",
       "2          0.0     30.09          5.8       16.0  53.799129    23.0  \n",
       "3          0.0     30.09          5.8       16.0  53.799129    23.0  \n",
       "4          0.0     30.09          5.8       16.0  53.799129    23.0  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A quick snapshot of our final dataframe\n",
    "train_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffcc1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and y variables for our train split\n",
    "X = train_transformed.drop(columns='wnvpresent')\n",
    "y = train_transformed['wnvpresent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "977bc405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a train-test split of 70-30 for train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    stratify=y, # Because this is an unbalanced dataset\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3535f4ab",
   "metadata": {},
   "source": [
    "**Polynomial Features**\n",
    "\n",
    "We have accounted for the interactions between different features. Model results were not very different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d74a7d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generates the full polynomial feature table\n",
    "# pf = PolynomialFeatures(include_bias=False, degree=2)\n",
    "# X_train_pf = pf.fit_transform(X_train)\n",
    "\n",
    "# # Adds appropriate feature names to all polynomial features\n",
    "# X_train_pf = pd.DataFrame(X_train_pf, columns=pf.get_feature_names(X_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f550bc9a",
   "metadata": {},
   "source": [
    "**Solving the problem with an unbalanced dataset** \n",
    "\n",
    "In classification problems, balancing your data is absolutely crucial. Data is said to be imbalanced when instances of one class outnumber the other(s) by a large proportion. One of the sampling techniques that we have decided to employ is **SMOTE** (Synthetic Minority Over-Sampling Technique).\n",
    "\n",
    "Just like the name suggests, the technique generates synthetic data for the minority class. SMOTE proceeds by joining the points of the minority class with line segments and then places artificial points on these lines. Here's how it works:\n",
    "\n",
    "* Choose a minority class input vector\n",
    "* Find its k nearest neighbors (k_neighbors is specified as an argument in the SMOTE() function)\n",
    "* Choose one of these neighbors and place a synthetic point anywhere on the line joining the point under consideration and its chosen neighbor\n",
    "* Repeat the steps until data is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d66fc91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to run model with standard scaling, SMOTE sampling, \n",
    "# with an option to run grid search, model and print results\n",
    "\n",
    "def run_model(mod, mod_params={}, grid_search=False):\n",
    "    \n",
    "    # Initial dictionary to hold model results\n",
    "    results = {}\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "            ('ss', StandardScaler()),\n",
    "            (mod, models[mod])\n",
    "            ])\n",
    "    \n",
    "    if grid_search:\n",
    "        # Instantiate list to store gridsearch results\n",
    "        gs = GridSearchCV(pipe, param_grid=mod_params, cv=5, verbose=1, scoring='roc_auc', n_jobs=-1)\n",
    "        gs.fit(X_train, y_train)\n",
    "        pipe = gs\n",
    "    else:\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "\n",
    "    # Retrieve metrics\n",
    "    predictions = pipe.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "    y_test_pred_prob = pipe.predict_proba(X_test)[:,1]\n",
    "    y_train_pred_prob = pipe.predict_proba(X_train)[:,1]\n",
    "    auc_scores = cross_val_score(pipe, X_train, y_train,  scoring='roc_auc', cv = 5)\n",
    "\n",
    "    results['model'] = mod\n",
    "    \n",
    "    results['train_auc_cv'] = auc_scores.mean()\n",
    "    \n",
    "    results['f1'] = f1_score(y_test, predictions)\n",
    "    results['recall'] = recall_score(y_test, predictions)        # % OF ACTUAL positives that are CORRECTLY predicted\n",
    "    results['precision'] = precision_score(y_test, predictions)  # % OF positives that are CORRECTLY predicted\n",
    "\n",
    "    results['train_auc'] = roc_auc_score(y_train, y_train_pred_prob)\n",
    "    results['test_auc'] = roc_auc_score(y_test, y_test_pred_prob)\n",
    "    results['auc_diff'] = results['train_auc'] - results['test_auc']\n",
    "\n",
    "    if grid_search:\n",
    "        gs_list.append(results)\n",
    "        print('### BEST PARAMS ###')\n",
    "        display(pipe.best_params_)\n",
    "        \n",
    "    else:\n",
    "        init_list.append(results)\n",
    "\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad13db53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Method Used: No sampling ----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Class Balance BEFORE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.9459\n",
       "1    0.0541\n",
       "Name: wnvpresent, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 5915\n",
      "\n",
      "Class Balance AFTER\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.9459\n",
       "1    0.0541\n",
       "Name: wnvpresent, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 5915 \n",
      "\n",
      "[21:00:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:00:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:00:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:00:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:00:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:00:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_auc_cv</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>auc_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dt</td>\n",
       "      <td>0.588817</td>\n",
       "      <td>0.226087</td>\n",
       "      <td>0.189781</td>\n",
       "      <td>0.279570</td>\n",
       "      <td>0.998899</td>\n",
       "      <td>0.590944</td>\n",
       "      <td>0.407954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.839769</td>\n",
       "      <td>0.189349</td>\n",
       "      <td>0.116788</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.969301</td>\n",
       "      <td>0.839621</td>\n",
       "      <td>0.129679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.797279</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.072993</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.998893</td>\n",
       "      <td>0.813458</td>\n",
       "      <td>0.185435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.821210</td>\n",
       "      <td>0.094595</td>\n",
       "      <td>0.051095</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.873107</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.059096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>et</td>\n",
       "      <td>0.735728</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.043796</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.998899</td>\n",
       "      <td>0.757477</td>\n",
       "      <td>0.241422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gb</td>\n",
       "      <td>0.832792</td>\n",
       "      <td>0.055172</td>\n",
       "      <td>0.029197</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.909630</td>\n",
       "      <td>0.829515</td>\n",
       "      <td>0.080114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.759705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.815812</td>\n",
       "      <td>0.744606</td>\n",
       "      <td>0.071206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svc</td>\n",
       "      <td>0.742393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.962577</td>\n",
       "      <td>0.736132</td>\n",
       "      <td>0.226444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  train_auc_cv        f1    recall  precision  train_auc  test_auc  \\\n",
       "0    dt      0.588817  0.226087  0.189781   0.279570   0.998899  0.590944   \n",
       "1   xgb      0.839769  0.189349  0.116788   0.500000   0.969301  0.839621   \n",
       "2    rf      0.797279  0.114286  0.072993   0.263158   0.998893  0.813458   \n",
       "3   ada      0.821210  0.094595  0.051095   0.636364   0.873107  0.814012   \n",
       "4    et      0.735728  0.071429  0.043796   0.193548   0.998899  0.757477   \n",
       "5    gb      0.832792  0.055172  0.029197   0.500000   0.909630  0.829515   \n",
       "6    lr      0.759705  0.000000  0.000000   0.000000   0.815812  0.744606   \n",
       "7   svc      0.742393  0.000000  0.000000   0.000000   0.962577  0.736132   \n",
       "\n",
       "   auc_diff  \n",
       "0  0.407954  \n",
       "1  0.129679  \n",
       "2  0.185435  \n",
       "3  0.059096  \n",
       "4  0.241422  \n",
       "5  0.080114  \n",
       "6  0.071206  \n",
       "7  0.226444  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Method Used: SMOTE sampling ----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Class Balance BEFORE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.9459\n",
       "1.0    0.0541\n",
       "Name: wnvpresent, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 5915\n",
      "\n",
      "Class Balance AFTER\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.5\n",
       "1.0    0.5\n",
       "Name: wnvpresent, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 11190 \n",
      "\n",
      "[21:05:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:05:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:05:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:05:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:05:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:05:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_auc_cv</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>auc_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gb</td>\n",
       "      <td>0.981540</td>\n",
       "      <td>0.261780</td>\n",
       "      <td>0.547445</td>\n",
       "      <td>0.172018</td>\n",
       "      <td>0.984820</td>\n",
       "      <td>0.812343</td>\n",
       "      <td>0.172477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svc</td>\n",
       "      <td>0.985760</td>\n",
       "      <td>0.240876</td>\n",
       "      <td>0.240876</td>\n",
       "      <td>0.240876</td>\n",
       "      <td>0.990639</td>\n",
       "      <td>0.772468</td>\n",
       "      <td>0.218171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.956751</td>\n",
       "      <td>0.239658</td>\n",
       "      <td>0.613139</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.959185</td>\n",
       "      <td>0.791350</td>\n",
       "      <td>0.167834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.993239</td>\n",
       "      <td>0.217617</td>\n",
       "      <td>0.153285</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.998321</td>\n",
       "      <td>0.838572</td>\n",
       "      <td>0.159749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.821628</td>\n",
       "      <td>0.180498</td>\n",
       "      <td>0.635036</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>0.827767</td>\n",
       "      <td>0.739272</td>\n",
       "      <td>0.088494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>et</td>\n",
       "      <td>0.988801</td>\n",
       "      <td>0.165049</td>\n",
       "      <td>0.124088</td>\n",
       "      <td>0.246377</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.770904</td>\n",
       "      <td>0.229033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.997149</td>\n",
       "      <td>0.164948</td>\n",
       "      <td>0.116788</td>\n",
       "      <td>0.280702</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.816768</td>\n",
       "      <td>0.183168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dt</td>\n",
       "      <td>0.955336</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.138686</td>\n",
       "      <td>0.172727</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.567881</td>\n",
       "      <td>0.432056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  train_auc_cv        f1    recall  precision  train_auc  test_auc  \\\n",
       "0    gb      0.981540  0.261780  0.547445   0.172018   0.984820  0.812343   \n",
       "1   svc      0.985760  0.240876  0.240876   0.240876   0.990639  0.772468   \n",
       "2   ada      0.956751  0.239658  0.613139   0.148936   0.959185  0.791350   \n",
       "3   xgb      0.993239  0.217617  0.153285   0.375000   0.998321  0.838572   \n",
       "4    lr      0.821628  0.180498  0.635036   0.105200   0.827767  0.739272   \n",
       "5    et      0.988801  0.165049  0.124088   0.246377   0.999937  0.770904   \n",
       "6    rf      0.997149  0.164948  0.116788   0.280702   0.999936  0.816768   \n",
       "7    dt      0.955336  0.153846  0.138686   0.172727   0.999937  0.567881   \n",
       "\n",
       "   auc_diff  \n",
       "0  0.172477  \n",
       "1  0.218171  \n",
       "2  0.167834  \n",
       "3  0.159749  \n",
       "4  0.088494  \n",
       "5  0.229033  \n",
       "6  0.183168  \n",
       "7  0.432056  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train_copy = X_train.astype(float).copy()\n",
    "y_train_copy = y_train.astype(float).copy()\n",
    "\n",
    "# create loop to run SMOTE sampling and compare the modelling outcomes with and without it\n",
    "for k in ['No', 'SMOTE']:\n",
    "    print('\\nMethod Used: {}'.format(k + ' sampling'), \"-\" * 100)\n",
    "        \n",
    "    print('\\nClass Balance BEFORE')\n",
    "    display(y_train.value_counts(normalize=True))\n",
    "    print('Number of rows: {}'.format(y_train.shape[0]))\n",
    "  \n",
    "    # instiantiate the models\n",
    "    methods = {'SMOTE': SMOTE(random_state=42)}\n",
    "    \n",
    "    if k == 'SMOTE':\n",
    "        mthd = methods[k]\n",
    "        X_train, y_train = mthd.fit_resample(X_train, y_train)\n",
    "\n",
    "    print('\\nClass Balance AFTER')\n",
    "    display(y_train.value_counts(normalize=True))\n",
    "    print('Number of rows: {}'.format(y_train.shape[0]),'\\n')\n",
    "    \n",
    "    \n",
    "    # Instiantiate models\n",
    "    models = {'lr': LogisticRegression(max_iter=5_000, random_state=42, solver='saga'),\n",
    "              'rf': RandomForestClassifier(random_state=42),\n",
    "              'gb': GradientBoostingClassifier(random_state=42),\n",
    "              'dt': DecisionTreeClassifier(random_state=42),\n",
    "              'et': ExtraTreesClassifier(random_state=42),\n",
    "              'ada': AdaBoostClassifier(random_state=42),\n",
    "              'svc': SVC(random_state=42, probability=True),\n",
    "              'xgb': XGBClassifier(random_state=42, \n",
    "                              objective='binary:logistic', \n",
    "                              verbosity=1, n_jobs=-1)\n",
    "            }\n",
    "\n",
    "    # Instantiate lists to store results\n",
    "    init_list = []\n",
    "    gs_list = []\n",
    "\n",
    "    for m in models:\n",
    "        run_model(m)\n",
    "    result_df = pd.DataFrame(init_list).sort_values(by=[\"f1\"], ascending=False).reset_index(drop=True)\n",
    "    display(result_df)\n",
    "\n",
    "    X_train = X_train_copy\n",
    "    y_train = y_train_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bb641d",
   "metadata": {},
   "source": [
    "## Selection of our final model (XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c63a4f",
   "metadata": {},
   "source": [
    "Due to the unbalanced nature of this dataset, the main metric on our radar is the ROC AUC. **XGBoost** fares scores pretty well on the validation set and requires less computational input compared to **ADABoost**.\n",
    "\n",
    "We will create a pipeline and tune some hyperparameters below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cab6a477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pipeline model for StandardScaler, SMOTE and XGBoost\n",
    "xgb_pipe = Pipeline([\n",
    "        ('ss', StandardScaler()),\n",
    "        ('xgb', XGBClassifier(random_state=42, \n",
    "                              objective= 'binary:logistic', \n",
    "                              verbosity=1, n_jobs=-1))\n",
    "    ])\n",
    "# Parameters\n",
    "xgb_params = {  'xgb__learning_rate': [0.1],\n",
    "                'xgb__max_depth': [40],\n",
    "                'xgb__min_child_weight': [25],\n",
    "                'xgb__gamma': [0.85],\n",
    "                'xgb__subsample': [1],\n",
    "                'xgb__scale_pos_weight': [63],\n",
    "                'xgb__n_estimators': [49]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8992a8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[21:05:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[21:05:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[21:05:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[21:05:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[21:05:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[21:05:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "### BEST PARAMS ###\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'xgb__gamma': 0.85,\n",
       " 'xgb__learning_rate': 0.1,\n",
       " 'xgb__max_depth': 40,\n",
       " 'xgb__min_child_weight': 25,\n",
       " 'xgb__n_estimators': 49,\n",
       " 'xgb__scale_pos_weight': 63,\n",
       " 'xgb__subsample': 1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 42.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgb_best = run_model('xgb', xgb_params, grid_search=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d79bbd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table to show the predictors with the highest importance (i.e. strongest predictors of the presence of WNV)\n",
    "feature_names = X.columns\n",
    "coefficients = pd.DataFrame(np.squeeze(xgb_best.best_estimator_.named_steps[\"xgb\"].feature_importances_),\n",
    "                            columns=['Importances']) \n",
    "features = pd.DataFrame(np.squeeze(feature_names), columns=['Features']) \n",
    "df = pd.concat([features, coefficients], axis='columns').sort_values('Importances', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de09c74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>week</td>\n",
       "      <td>0.130479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>month</td>\n",
       "      <td>0.053143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>cluster_31</td>\n",
       "      <td>0.033728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>PIPIENS</td>\n",
       "      <td>0.031945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cluster_4</td>\n",
       "      <td>0.031897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cluster_23</td>\n",
       "      <td>0.031414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>cluster_33</td>\n",
       "      <td>0.030620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>cluster_60</td>\n",
       "      <td>0.025945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>sealevel</td>\n",
       "      <td>0.025865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>cluster_73</td>\n",
       "      <td>0.025526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cluster_7</td>\n",
       "      <td>0.024153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cluster_18</td>\n",
       "      <td>0.023776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>resultspeed</td>\n",
       "      <td>0.023362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>cluster_61</td>\n",
       "      <td>0.022122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>cluster_41</td>\n",
       "      <td>0.021143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Features  Importances\n",
       "1          week     0.130479\n",
       "0         month     0.053143\n",
       "33   cluster_31     0.033728\n",
       "80      PIPIENS     0.031945\n",
       "6     cluster_4     0.031897\n",
       "25   cluster_23     0.031414\n",
       "35   cluster_33     0.030620\n",
       "62   cluster_60     0.025945\n",
       "87     sealevel     0.025865\n",
       "75   cluster_73     0.025526\n",
       "9     cluster_7     0.024153\n",
       "20   cluster_18     0.023776\n",
       "88  resultspeed     0.023362\n",
       "63   cluster_61     0.022122\n",
       "43   cluster_41     0.021143"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77c6f709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_prob = xgb_best.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve, ROC AUC Score: {}'.format(roc_auc_score(y_test, y_pred_prob).round(3)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184af3de",
   "metadata": {},
   "source": [
    "## Tidying ```test``` data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5a0490",
   "metadata": {},
   "source": [
    "We will need to import our test data and carry out the pre-requisite pre-processing steps. We have created custom functions for this bit of the codebook.\n",
    "* Initial cleaning (Dropping address, block, street, addressaccuracy columns)\n",
    "* Date feature engineering (Extracting year, month, week, day variables)\n",
    "* Dummify our ```cluster``` column\n",
    "* One-hot encoding mosquito species\n",
    "* Determining if a coordinate is closer to Station 1 or Station 2\n",
    "* Final cleaning (Dropping the remaining unnecessary columns)\n",
    "* Generating predictions from our best model\n",
    "\n",
    "After applying each function, we will map it to a new variable to ensure the process flows smoothly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf2eedcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train and test datasets\n",
    "test = pd.read_csv('../assets/cleaned/test_tidied.csv', parse_dates=['date'])\n",
    "\n",
    "# Converting columns to lowercase for standardisation\n",
    "test.columns = test.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6ea42d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics:\n",
      "Shape of dataframe: (116293, 13)\n",
      "--------------------------------------\n",
      "Null values in dataframe: 0\n",
      "--------------------------------------\n",
      "% of Null values in dataframe: 0.0%\n",
      "--------------------------------------\n",
      "Total duplicate rows: 0\n",
      "--------------------------------------\n",
      "% duplicate rows: 0.0%\n",
      "\n",
      "Column names: Index(['id', 'date', 'address', 'species', 'block', 'street', 'trap',\n",
      "       'addressnumberandstreet', 'latitude', 'longitude', 'addressaccuracy',\n",
      "       'coord', 'cluster'],\n",
      "      dtype='object')\n",
      "\n",
      "Variable Types\n",
      "Columns Count: \n",
      "object            6\n",
      "int64             4\n",
      "float64           2\n",
      "datetime64[ns]    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Previewing our test dataset\n",
    "eda_clean(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55ff6a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_clean(df):\n",
    "    df.drop(columns=['address', 'block', 'street', 'addressaccuracy'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c57ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter1 = initial_clean(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4804972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_feature_engineering(df):\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['week'] = df['date'].dt.isocalendar().week\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['year_month'] = df['date'].dt.strftime(\"%Y-%m\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "895676e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter2 = date_feature_engineering(test_iter1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8df4a96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter3 = pd.get_dummies(test_iter2, columns=['cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "683cc2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can exclude Unsepcified species from this selection\n",
    "species_of_interest = ['RESTUANS', 'PIPIENS', \n",
    "                       'SALINARIUS', 'TERRITANS', 'TARSALIS', 'ERRATICUS'\n",
    "                      ]\n",
    "\n",
    "# create loop to create dummified variables to indicate presence of Pipiens & Restuans species\n",
    "def dummify_species(df):\n",
    "    for i in species_of_interest:\n",
    "        df[i] = df['species'].apply(lambda x: 1 if i in x else 0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3c1dd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter4 = dummify_species(test_iter3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d165be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_station(lat, long):\n",
    "    station1 = (41.995, -87.933) #Chicago O'Hare Tntl Airpot -> lat: 41.995 long: -87.933\n",
    "    station2 = (41.786, -87.752) #Chicago Midway Tntl Airpot -> lat: 41.786 long: -87.752\n",
    "    coordinates = (lat, long)\n",
    "    \n",
    "    return 1 if geodesic(coordinates, station1) < geodesic(coordinates, station2) else 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb335dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Apply function to map our function\n",
    "test_iter4['station_ref'] = test_iter4.apply(lambda i: determine_station(i['latitude'], i['longitude']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5181f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tidied weather dataset\n",
    "weather_tidied = pd.read_csv('../assets/cleaned/weather_tidied.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "572cdbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter5 = test_iter4.merge(weather_tidied, how='left', left_on=['station_ref', 'date'], right_on=['station', 'date'])\n",
    "test_iter5.drop(columns=[\"station\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5ac4199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_clean(df):\n",
    "    df.drop(columns=['species', 'trap', 'date', 'addressnumberandstreet', \n",
    "                     'latitude', 'longitude', \n",
    "                     'day', 'coord',\n",
    "                     'year_month', 'station_ref', 'year'], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "262505d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter6 = final_clean(test_iter5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b7a2b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_best(df, model_best):\n",
    "    df_id = df['id']\n",
    "\n",
    "    df_base = df.drop(columns=['id'])\n",
    "    \n",
    "    # generate predictions\n",
    "    y_pred = model_best.best_estimator_.predict(df_base)  \n",
    "\n",
    "    # load prediction into dataframe\n",
    "    df_pred = pd.DataFrame(y_pred, columns=['wnvpresent']) \n",
    "\n",
    "    # Merge id with predictions into one dataframe\n",
    "    df_final = pd.concat([df_id, df_pred], axis='columns')\n",
    "    return df_final\n",
    "\n",
    "def predict_proba_best(df, model_best):\n",
    "    df_coord = test[['latitude', 'longitude']]\n",
    "    \n",
    "    df_base = df.drop(columns=['id'])\n",
    "    \n",
    "    # generate predictions\n",
    "    y_pred = model_best.best_estimator_.predict_proba(df_base)  \n",
    "\n",
    "    # load prediction into dataframe\n",
    "    df_pred = pd.DataFrame(np.squeeze(y_pred)) \n",
    "\n",
    "    # Merge id with predictions into one dataframe\n",
    "    df_final = pd.concat([df_coord, df_pred], axis='columns')\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afdcad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions\n",
    "pred = predict_best(test_iter6, xgb_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a56a724",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.rename(columns={'id': 'Id', 'wnvpresent':'WnvPresent'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36b92ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.set_index('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "320e2abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_csv('../kaggle/submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67897e90",
   "metadata": {},
   "source": [
    "**Kaggle Submission Score**\n",
    "\n",
    "**Thoughts**: We believe further improvements can be made to the model (if given enough time). Here are some of our considerations:\n",
    "* There could be a bias for certain traps (Given that a particular trap may always capture more mosquitos, etc)\n",
    "* Possibility of a daily multiplier given an array of outbreaks; Outbreaks will possibly influence the days before and after it (They tend to cluster in the dimension of time too)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26adaefc",
   "metadata": {},
   "source": [
    "![Our Kaggle submission](../images/kaggle_submission.png \"Our Kaggle submission\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
